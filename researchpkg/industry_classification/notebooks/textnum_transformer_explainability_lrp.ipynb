{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595234ab",
   "metadata": {},
   "source": [
    "# TextNum Transformer Explainability \n",
    "-----------------------------------\n",
    "\n",
    "Explanability analysis of textnum transformer output using Layer-wise Relevance Propagation (LRP) : https://arxiv.org/abs/2012.09838\n",
    "\n",
    "https://colab.research.google.com/github/hila-chefer/Transformer-Explainability/blob/main/BERT_explainability.ipynb#scrollTo=4-XGl_Zw6Aht\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c795d033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/hila-chefer/Transformer-Explainability.git\n",
    "\n",
    "# # import os\n",
    "# # os.chdir(f'./Transformer-Explainability')\n",
    "# import sys\n",
    "# sys.path.append('./Transformer-Explainability')\n",
    "\n",
    "# # !pip install -r requirements.txt\n",
    "# # !pip install captum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ed8c69",
   "metadata": {},
   "source": [
    "# Load the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0dd11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from researchpkg.industry_classification.config import *\n",
    "from researchpkg.industry_classification.utils.experiment_utils import (\n",
    "    ExperimentUtils,\n",
    ")\n",
    "\n",
    "EXPERIMENT_NAME = \"lrp_transformer_encoder_finlangl0_row933_h8_l4_e64_f256_d0.0_proj768___sic1_max_tag_depth_5\"\n",
    "EXPERIMENT_DIR =  os.path.join(LOGS_DIR,\"experiments_count30_sic1agg_including_is_2023\",EXPERIMENT_NAME)                               \n",
    "assert os.path.exists(EXPERIMENT_DIR), \"Provided experiment dir does not exists\"\n",
    "\n",
    "experiment_config = ExperimentUtils.load_experiment_data(EXPERIMENT_DIR)\n",
    "model_config = experiment_config[\"model_config\"]\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88627c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from researchpkg.industry_classification.models.transformers.textnum_transformer import TextNumTransformerForClassification\n",
    "model = TextNumTransformerForClassification(\n",
    "        n_accounts= model_config[\"n_accounts\"],\n",
    "        pretrained_model=model_config[\"pretrained_model\"],\n",
    "        n_head=model_config[\"n_head\"],\n",
    "        n_layers=model_config[\"n_layers\"],\n",
    "        n_classes=model_config[\"n_classes\"],\n",
    "        emb_dim=model_config[\"emb_dim\"],\n",
    "        ffw_dim=model_config[\"ffw_dim\"],\n",
    "        learning_rate=model_config[\"learning_rate\"],\n",
    "        class_names=model_config[\"class_names\"],\n",
    "        dropout_rate=model_config[\"dropout_rate\"],\n",
    "        trf_trainable_layers=model_config[\"trf_trainable_layers\"],\n",
    "        use_lrp_modules = model_config[\"use_lrp_modules\"],\n",
    "    ).cuda()\n",
    "\n",
    "\n",
    "#Load the best model\n",
    "print(\"Loading the best model\")\n",
    "ckpt_file = ExperimentUtils.get_best_model( os.path.basename(EXPERIMENT_DIR),os.path.dirname(EXPERIMENT_DIR),)[\"path\"]\n",
    "ckpt_file = os.path.join(ROOT_DIR,ckpt_file)\n",
    "assert os.path.exists(ckpt_file), f\"{ckpt_file} do not exists\"\n",
    "model  = model.load_from_checkpoint(ckpt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac85ff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c543c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d7697",
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664088e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from researchpkg.industry_classification.dataset.sec_textnum_transformer_datamodule import SecTrfClassificationDataModule\n",
    "\n",
    "\n",
    "dataset_config = ExperimentUtils.load_experiment_data(EXPERIMENT_DIR)[\n",
    "    \"dataset_config\"\n",
    "]\n",
    "dataset_dir = os.path.join(SEC_ROOT_DATA_DIR,\"count30_sic1agg_including_is_2023\")d\n",
    "# dataset_dir =\"/home/test/servlilleg5k//researchpkg/industry_classification/data/sec_data_v2/count30_sic1agg_including_is_2023\"\n",
    "\n",
    "datamodule = SecTrfClassificationDataModule(\n",
    "    dataset_dir,\n",
    "    batch_size=32,\n",
    "    num_workers=2,\n",
    "    sic_digits=1,\n",
    "    tokenizer=model.tokenizer,\n",
    "    use_change=True,\n",
    "    load_in_memory=False,\n",
    "    max_desc_len=32,\n",
    "    max_tags=dataset_config[\"max_nb_tag_per_sheet\"],\n",
    "    balance_sampling=False,\n",
    "    max_tag_depth=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58387e59",
   "metadata": {},
   "source": [
    "# LRP Explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59581a95",
   "metadata": {},
   "source": [
    "## Prepare the textnum transformer to use LRP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066c492",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monkey patch the generate LRP method to support textnum transformer interface.\n",
    "%autoreload\n",
    "from researchpkg.industry_classification.models.transformers.bert_explainability_modules.BERT_explainability.modules.BERT.ExplanationGenerator import Generator, compute_rollout_attention\n",
    "import numpy as np, torch \n",
    "import types\n",
    "explanations = Generator(model)\n",
    "\n",
    "def generate_LRP_for_textnum(self, textnum_enc, input_attn_mask,\n",
    "                    index=None, start_layer=1):\n",
    "    output = self.model.forward_only_textnum(textnum_enc, input_attn_mask)\n",
    "    kwargs = {\"alpha\": 1}\n",
    "\n",
    "    if index == None:\n",
    "        index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "    one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "    one_hot[0, index] = 1\n",
    "    one_hot_vector = one_hot\n",
    "    one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "    one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "    self.model.zero_grad()\n",
    "    one_hot.backward(retain_graph=True)\n",
    "\n",
    "    self.model.relprop(torch.tensor(one_hot_vector).to(textnum_enc.device), **kwargs)\n",
    "\n",
    "    cams = []\n",
    "    blocks = self.model.text_num_transformer.layer\n",
    "    for blk in blocks:\n",
    "        grad = blk.attention.self.get_attn_gradients()\n",
    "        cam = blk.attention.self.get_attn_cam()\n",
    "        cam = cam[0].reshape(-1, cam.shape[-1], cam.shape[-1])\n",
    "        grad = grad[0].reshape(-1, grad.shape[-1], grad.shape[-1])\n",
    "        cam = grad * cam\n",
    "        cam = cam.clamp(min=0).mean(dim=0)\n",
    "        cams.append(cam.unsqueeze(0))\n",
    "    rollout = compute_rollout_attention(cams, start_layer=start_layer)\n",
    "    rollout[:, 0, 0] = rollout[:, 0].min()\n",
    "    return rollout[:, 0]\n",
    "\n",
    "explanations.generate_LRP = types.MethodType(generate_LRP_for_textnum, explanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f49fe",
   "metadata": {},
   "source": [
    "## Explanation generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_to_idx = {os.path.basename(datamodule.test_dataset.data_files[i]):i for i in range(len(datamodule.test_dataset.data_files))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_to_idx[\"0000010254-23-000058_2023_q1.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594b73584b5f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.test_dataset.data_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d885b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from typing import Iterable\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import re\n",
    "def split_by_capital_letter(tag) -> str:\n",
    "        \"\"\"\n",
    "        Separate a tag by capital letters(Adding a space)\n",
    "        :param tag: The tag to separate\n",
    "        :return: The separated tag\n",
    "        \"\"\"\n",
    "        return re.sub(r\"([A-Z])\", r\" \\1\", tag).strip()\n",
    "\n",
    "def visualize_text_multirow(\n",
    "    account_datarecord: visualization.VisualizationDataRecord,\n",
    "    amount_datarecord: visualization.VisualizationDataRecord,\n",
    "    legend: bool = True\n",
    ") -> \"HTML\":  # In quotes because this type doesn't exist in standalone mode\n",
    "\n",
    "    def _get_row_color(attr):\n",
    "        # clip values to prevent CSS errors (Values should be from [-1,1])\n",
    "        attr = max(-1, min(1, attr))\n",
    "        if attr >= 0:\n",
    "            hue = 120\n",
    "            sat = 75\n",
    "            lig = 100 - int(60 * attr)\n",
    "        else:\n",
    "            raise ValueError(\"Only positive values are supported\")\n",
    "        return \"hsl({}, {}%, {}%)\".format(hue, sat, lig)\n",
    "\n",
    "\n",
    "     # Add ground truth label, pred label attributions\n",
    "     \n",
    "    dom = [\"<table style=' border: 1px solid black; border-collapse: ;'>\"]\n",
    "    rows = [\n",
    "        \"<tr>\",\n",
    "        \"<th style='border: 1px solid black; padding: 8px;'>Ground Truth</th>\",\n",
    "        \"<th style='border: 1px solid black; padding: 8px;'>Predicted</th>\",\n",
    "        \"<th style='border: 1px solid black; padding: 8px;'>Attribution Score</th>\",\n",
    "        \"</tr>\"\n",
    "         f\"<tr style='background-color: white;'>\",\n",
    "            f\"<td style='border: 1px solid black; padding: 2px;'>{visualization.format_classname(account_datarecord.true_class)}</td>\",\n",
    "            f\"<td style='border: 1px solid black; padding: 2px;'>{account_datarecord.pred_class} ({account_datarecord.pred_prob:.2f})</td>\",\n",
    "            f\"<td style='border: 1px solid black; padding: 2px;'>{account_datarecord.attr_score:.2f}</td>\",\n",
    "            \"</tr>\"\n",
    "    ]\n",
    "\n",
    "    \n",
    "    # Closing the HTML table\n",
    "    dom.append(\"\".join(rows))\n",
    "    dom.append(\"</table>\")\n",
    "            \n",
    "    \n",
    "    # Begin the HTML for the table (on a 2 column )\n",
    "    dom.append(\"<table style='table-layout: fixed; width: 50%; border: 3px solid black; border-collapse: collapse;'>\")\n",
    "        \n",
    "\n",
    "    # Add table headers\n",
    "    rows = [\n",
    "        \"<tr>\",\n",
    "        \"<th style='border: 1px solid black; padding: 8px; font-size:19px; font-weight:bold ' >Tag</th>\",\n",
    "        \"<th  style='border: 1px; solid black; padding: 8px; font-size:19px; font-weight:bold'>Amount</th>\",\n",
    "        \"</tr>\"\n",
    "    ]\n",
    "\n",
    "    # Iterate over the provided data records and populate the table\n",
    "    for i in range(len(account_datarecord.word_attributions)):\n",
    "        account_word = account_datarecord.raw_input_ids[i]\n",
    "        account_word = split_by_capital_letter(account_word)\n",
    "        \n",
    "        account_amount = amount_datarecord.raw_input_ids[i]\n",
    "        account_amount = \"${:,.0f}\".format(account_amount)\n",
    "        score = amount_datarecord.word_attributions[i]\n",
    "        background_color = _get_row_color(score)\n",
    "        \n",
    "        rows.append(\n",
    "            \"\".join(\n",
    "                [\n",
    "                    f\"<tr style='background-color: {background_color};'>\",\n",
    "                    f\"<td style='word-wrap: break-word; border: 1px solid black; padding:8px;font-size:18px; height:30px'>{account_word}</td>\",\n",
    "                    f\"<td style='border: 1px solid black;  padding:4px; font-size:18px; '>{account_amount}</td>\",\n",
    "                    \"</tr>\"\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Add legend if necessary\n",
    "    if legend:\n",
    "        dom.append(\n",
    "            '<div style=\"border-top: 1px solid; margin-top: 5px; \\\n",
    "            padding-top: 5px; display: inline-block\">'\n",
    "        )\n",
    "        dom.append(\"<b>Legend: </b>\")\n",
    "\n",
    "        for value, label in zip([ 0, 1], [ \"Neutral\", \"Positive\"]):\n",
    "            color = _get_row_color(value)\n",
    "            dom.append(\n",
    "                f'<span style=\"display: inline-block; width: 10px; height: 10px; \\\n",
    "                border: 1px solid; background-color: {color};\"></span> {label}  '\n",
    "            )\n",
    "        dom.append(\"</div>\")\n",
    "\n",
    "    # Close the HTML table\n",
    "    dom.append(\"\".join(rows))\n",
    "    dom.append(\"</table>\")\n",
    "\n",
    "    # Convert list to a single HTML string\n",
    "    html = HTML(\"\".join(dom))\n",
    "\n",
    "    # Display the HTML in IPython\n",
    "    display(html)\n",
    "    return html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2292fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = model_config[\"class_names\"]\n",
    "\n",
    "\n",
    "def explain_sample(sample):\n",
    "    # Splitting and sorting tags\n",
    "    tags = sample[\"tags\"].split(\";\")\n",
    "    sorted_indices = sorted(range(len(tags)), key=lambda i: tags[i])\n",
    "    # sorted_indices = list(range(len(tags)))\n",
    "    # Sorting and aligning other inputs based on the sorted indices\n",
    "    tags = [tags[i] for i in sorted_indices]\n",
    "    input_desc = sample[\"input_desc\"][sorted_indices].to(model.device).unsqueeze(0)\n",
    "    input_net_change = sample[\"input_net_change\"][sorted_indices].to(model.device).unsqueeze(0)\n",
    "    input_attn_mask = sample[\"input_attn_mask\"][sorted_indices].to(model.device).unsqueeze(0)\n",
    "    \n",
    "    input_desc = sample[\"input_desc\"].to(model.device).unsqueeze(0)\n",
    "    input_net_change = sample[\"input_net_change\"].to(model.device).unsqueeze(0)\n",
    "    input_attn_mask = sample[\"input_attn_mask\"].to(model.device).unsqueeze(0)\n",
    "\n",
    "    \n",
    "    y_true = sample[\"target\"].item()\n",
    "    textnum_enc = model.forward(\n",
    "        input_desc=input_desc,\n",
    "        input_net_change=input_net_change,\n",
    "        input_attn_mask=input_attn_mask,\n",
    "        return_text_num_enc=True\n",
    "    )\n",
    "\n",
    "    # Generating explanations\n",
    "    expl = explanations.generate_LRP(\n",
    "        textnum_enc=textnum_enc, input_attn_mask=input_attn_mask, start_layer=3\n",
    "    ).squeeze()\n",
    "    expl = expl[:len(tags)]\n",
    "\n",
    "    # Normalize scores\n",
    "    expl = (expl - expl.min()) / (expl.max() - expl.min())\n",
    "    \n",
    "    output = torch.nn.functional.softmax(\n",
    "        model.forward(\n",
    "            input_desc=input_desc,\n",
    "            input_net_change=input_net_change,\n",
    "            input_attn_mask=input_attn_mask\n",
    "        ), dim=-1 \n",
    "    )\n",
    "    y_pred = output.argmax(dim=-1).item()\n",
    "\n",
    "    # Formatting functions\n",
    "    net_changes = sample[\"input_net_change\"].cpu().squeeze()[sorted_indices]\n",
    "    net_changes = datamodule.test_dataset.revert_log_scaling_transform(net_changes)\n",
    "\n",
    "    textnum_pseudo_tokens = [\n",
    "        tags[i] + \" : \" + str(net_changes[i].item()) for i in range(len(tags))\n",
    "    ]\n",
    "\n",
    "    return expl, output.squeeze(), y_true, y_pred, textnum_pseudo_tokens, tags, net_changes\n",
    "\n",
    "\n",
    "def visualize_explained_sample(i):\n",
    "    expl, output, y_true, y_pred, textnum_pseudo_tokens,tags, net_changes = explain_sample(datamodule.test_dataset[i])\n",
    "\n",
    "    account_record =  visualization.VisualizationDataRecord(\n",
    "                                    expl,\n",
    "                                    output[y_pred],\n",
    "                                    class_names[y_pred],\n",
    "                                    class_names[y_true],\n",
    "                                    y_pred,\n",
    "                                    1,\n",
    "                                    tags,\n",
    "                                    1)\n",
    "    amount_record = visualization.VisualizationDataRecord(\n",
    "                                    expl,\n",
    "                                    output[y_pred],\n",
    "                                    class_names[y_pred],\n",
    "                                    class_names[y_true],\n",
    "                                    y_pred,\n",
    "                                    1,#Sum to 1  textnum_pseudo_tokens\n",
    "                                    [net_changes[i].item() for i in range(len(tags))],\n",
    "                                    1)\n",
    "    print(\"y_pred:\",class_names[y_pred], \"\\ny_true:\", class_names[y_true])\n",
    "\n",
    "    visualize_text_multirow(account_record, amount_record, legend=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d146c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"0001410578-23-000236_2023_q1.csv\"\n",
    "sample = filename_to_idx[filename]\n",
    "visualize_explained_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5efbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be140121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

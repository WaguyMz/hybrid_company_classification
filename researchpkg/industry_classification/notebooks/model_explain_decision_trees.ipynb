{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b1bdd7b-6616-42fc-99d8-7e2bc5879bc9",
   "metadata": {},
   "source": [
    "# Decisions tree model explain\n",
    "---------------\n",
    "\n",
    "Compute features importance for GBDT models : LightGBM and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888dae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from researchpkg.industry_classification.config import *\n",
    "import numpy as np\n",
    "from researchpkg.industry_classification.dataset.sec_datamodule import *\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1)\n",
    "from researchpkg.industry_classification.utils.sics_loader import load_sic_codes\n",
    "import lightgbm\n",
    "from researchpkg.industry_classification.models.utils import NN_Utils\n",
    "from researchpkg.industry_classification.models.decision_trees.lgbm import LgbmForSicClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84336304-fa9f-49a0-b778-129d0bcb7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Color map\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707f7e5",
   "metadata": {},
   "source": [
    "# 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(SEC_ROOT_DATA_DIR,\"count30_sic1agg_including_is_2023\")\n",
    "# checkpoint_path  = os.path.join(experiment_dir,\"model.lgbm\"\n",
    "MAX_TAG_DEPTH = 5\n",
    "NORMALIZATION = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67083103-3b45-4868-8ed6-7959bce59fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sics_ref =load_sic_codes()\n",
    "sics_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77602a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from researchpkg.industry_classification.dataset.sec_gbdt_dataset import SecGBDTDataset\n",
    "sic_digits = 1\n",
    "sics_dict = sics_ref.set_index(f\"sic\").industry_title.to_dict()\n",
    "\n",
    "#3. Load accounts index\n",
    "\n",
    "accounts_index, registrants_index,_ = \\\n",
    "    SecDataset.load_index(dataset_dir,sic_digits=sic_digits)\n",
    "sic_labels = list(sorted(registrants_index[f\"sic{sic_digits}\"].unique().tolist()))\n",
    "\n",
    "\n",
    "train_dataset = SecGBDTDataset(\n",
    "        dataset_dir,\n",
    "        DatasetType.TRAIN,\n",
    "        sic_digits=sic_digits,\n",
    "        normalization_type=NORMALIZATION,\n",
    "        max_tag_depth=MAX_TAG_DEPTH\n",
    "    )\n",
    "val_dataset = SecGBDTDataset(\n",
    "    dataset_dir,\n",
    "    DatasetType.VAL,\n",
    "    sic_digits=sic_digits,\n",
    "    normalization_type=NORMALIZATION,\n",
    "    max_tag_depth=MAX_TAG_DEPTH\n",
    ")\n",
    "test_dataset = SecGBDTDataset(\n",
    "    dataset_dir,\n",
    "    DatasetType.TEST,\n",
    "    sic_digits=sic_digits,\n",
    "    normalization_type=NORMALIZATION,\n",
    "    max_tag_depth=MAX_TAG_DEPTH\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b2f5ba-fc93-4c62-8d15-60b89e318399",
   "metadata": {},
   "source": [
    "# 2. Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63082c33-e361-4f4e-995e-26aecf3d214f",
   "metadata": {},
   "source": [
    "## 2.1. Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a2c50-8f8f-4d8b-91f7-74e5a62fe481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from researchpkg.industry_classification.utils.experiment_utils import ExperimentUtils\n",
    "import os\n",
    "import shutil\n",
    "experiment_dir = \"/tmp/experiment_dir\"\n",
    "\n",
    "if os.path.exists(experiment_dir):\n",
    "    shutil.rmtree(experiment_dir)\n",
    "    \n",
    "\n",
    "features_name = accounts_index[\"tag\"].tolist()\n",
    "\n",
    "sic_reverse_index = {v: k for k, v in train_dataset.sic_id_index.items()}\n",
    "labels = np.unique(train_dataset.Y).tolist()\n",
    "labels = [sic_reverse_index[l] for l in labels]\n",
    "sic_code_df = load_sic_codes()[[\"sic\", \"industry_title\"]]\n",
    "n_labels = len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d87193",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = MAX_TAG_DEPTH\n",
    "n_estimators= 100\n",
    "num_leaves = 60\n",
    "\n",
    "# max_depth=4\n",
    "# num_leavers=16\n",
    "# n_estimators=1\n",
    "\n",
    "learning_rate= 0.05\n",
    "n_jobs=8\n",
    "boosting_type=\"gbdt\"\n",
    "seed=42\n",
    "experiment_name=\"model_explain\"\n",
    "accelerator=\"cuda\"\n",
    "global_exp_name = \"count30_sic1agg_including_is_2023\"\n",
    "normalization=NORMALIZATION\n",
    "\n",
    "ExperimentUtils.check_global_experiment_name(global_exp_name)\n",
    "dataset_dir = os.path.join(SEC_ROOT_DATA_DIR, f\"{global_exp_name}\")\n",
    "experiments_dir = os.path.join(LOGS_DIR, f\"experiments_{global_exp_name}\")\n",
    "#Train and test the model\n",
    "X_train, Y_train = train_dataset.X, train_dataset.Y\n",
    "X_val, Y_val = val_dataset.X, val_dataset.Y\n",
    "X_test, Y_test = test_dataset.X, test_dataset.Y\n",
    "\n",
    "# Ensure all y_val labels appears at least once in Y_train\n",
    "all_y_train_labels = np.unique(Y_train)\n",
    "index = np.isin(Y_val, all_y_train_labels)\n",
    "X_val = X_val[index]\n",
    "Y_val = Y_val[index]\n",
    "\n",
    "index_test = np.isin(Y_test, all_y_train_labels)\n",
    "X_test = X_test[index_test]\n",
    "Y_test = Y_test[index_test]\n",
    "\n",
    "\n",
    "# Compute class weights\n",
    "# class_weights = SecDataset.calculate_class_weights(Y_train.tolist(),beta=0.1)\n",
    "# class_weights = SecDataset.calculate_class_weights(Y_train.tolist())\n",
    "\n",
    "# 2. Load the model.\n",
    "model = LgbmForSicClassification(\n",
    "    n_accounts=len(features_name),\n",
    "    n_classes=n_labels,\n",
    "    num_leaves=num_leaves,\n",
    "    max_depth=max_depth,\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate=learning_rate,\n",
    "    n_jobs=n_jobs,\n",
    "    features_name=features_name,\n",
    "    class_names=labels,\n",
    "    boosting_type=boosting_type,\n",
    "    seed=seed,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "    \n",
    "experiment_name = f\"{model.__name__}{experiment_name}_sic{sic_digits}_balanced\"\n",
    "experiment_name = f\"{experiment_name}_scaling.{normalization}\"\n",
    "\n",
    "if max_depth:\n",
    "    experiment_name = f\"{experiment_name}_max_depth{max_depth}\"\n",
    "\n",
    "# 3. Trainer\n",
    "experiment_dir = os.path.join(experiments_dir, experiment_name)\n",
    "\n",
    "\n",
    "if not ExperimentUtils.check_experiment(experiment_dir):\n",
    "    # 4. Initialize the experiment\n",
    "    ExperimentUtils.initialize_experiment(\n",
    "        experiment_dir,\n",
    "        dataset_dir,\n",
    "        model.hparams,\n",
    "        training_config={\n",
    "            \"num_jobs\": n_jobs,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"seed\": seed,\n",
    "            \"device\": accelerator,\n",
    "            \"ngpus\": torch.cuda.device_count() if accelerator == \"cuda\" else 0,\n",
    "        },\n",
    "    )\n",
    "\n",
    "# model.train_top_k(X_train, Y_train, X_val, Y_val, experiment_dir=experiment_dir,\n",
    "#             accelerator=accelerator,top_k=3\n",
    "#             )\n",
    "\n",
    "model.train(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    X_val,\n",
    "    Y_val,\n",
    "    experiment_dir=experiment_dir,\n",
    "    accelerator=accelerator,\n",
    ")\n",
    "\n",
    "model.test(X_test, Y_test, experiment_dir=experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df307b11-b8b9-496e-9336-f3f32d403880",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_pred = model.predict(X_val)\n",
    "res_file =  os.path.join(experiment_dir,\"results.yaml\")\n",
    "import pyaml\n",
    "from yaml import Loader\n",
    "res  = pyaml.yaml.load(open(res_file, 'r'),\n",
    "                               Loader=Loader\n",
    "                               )\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf9489a-2408-4cc1-87a9-9ad11790c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(all_y_true,all_y_pred,):\n",
    "        # Compute and plot the confusion matrix at the end of the training.\n",
    "        \n",
    "        cm_plot = NN_Utils.compute_confusion_matrix(all_y_true, all_y_pred,\n",
    "                                                        model.class_names)\n",
    "        \n",
    "        cm_plot_normalized =  NN_Utils.compute_confusion_matrix(all_y_true, all_y_pred,\n",
    "                                                        model.class_names, normalize=True)\n",
    "        \n",
    "        \n",
    "\n",
    "plot_confusion_matrix(Y_val, Y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f8375e-5e48-4981-979f-5d8d3500d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confusion matrix on train samples\n",
    "# Y_train_pred = model.predict(X_train)\n",
    "# plt.tight_layout()\n",
    "# plot_confusion_matrix(Y_train, Y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7c0a10",
   "metadata": {},
   "source": [
    "# 3.  Compute features importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def plotImp(model,top_k= 20, fig_size = (40, 20), importance_type = 'split'):\n",
    "    feature_imp = pd.DataFrame({'Value':model.model.booster_.feature_importance(importance_type=importance_type),'Feature':model.model.booster_.feature_name()})\n",
    "    plt.figure(figsize=fig_size)\n",
    "    \n",
    "    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n",
    "                                                        ascending=False)[0:top_k])\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f65a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImp(model,top_k=20,fig_size=(15,8),importance_type='split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a198ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotImp(model,top_k=20,fig_size=(30,20),importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c2558",
   "metadata": {},
   "source": [
    "# 4. Plot decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff89e8b-04e0-442b-a404-2b77b4bb8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.booster_.trees_to_dataframe().tree_index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9a7bf-a84a-4b23-8cf3-210e003951e5",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install graphviz\n",
    "lightgbm.plot_tree(model.model.booster_, figsize=(40,20), dpi=500, show_info=['internal value'], orientation=\"vertical\",tree_index=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb774c2d",
   "metadata": {},
   "source": [
    "# 5. Lime explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01af4f-4cbd-4e10-b088-7ce11570de98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9bc6a-30aa-4d00-ad73-dc834a164171",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset.X\n",
    "Y_train = train_dataset.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e185ef-9fb1-4f20-bf2b-361317c4872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_index, registrants_index,_ = \\\n",
    "        SecDataset.load_index(dataset_dir,sic_digits=sic_digits)\n",
    "labels  = sorted(registrants_index[f\"sic{sic_digits}\"].unique().tolist())\n",
    "feature_names = accounts_index.tag.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b18382-11e6-4483-a5e2-918845b53ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train ,feature_names = feature_names,class_names=labels,\n",
    "                                                   training_labels=labels,\n",
    "                                                   kernel_width=3)\n",
    "predict_fn = lambda x: model.model.predict_proba(np.exp(x)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb992f-cd87-4654-af64-199891982be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = X_train[0]\n",
    "exp = explainer.explain_instance(chosen, predict_fn,num_features=490)\n",
    "# exp.show_in_notebook(show_all=False,show_predicted_value=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b931b0-18d1-4b91-af52-e9bb42a6fb20",
   "metadata": {},
   "source": [
    "# 6. Analysis Results on Class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b92b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_sic_2= SecGBDTDataset(dataset_dir, DatasetType.VAL,sic_digits=2)\n",
    "train_dataset_sic_2 = SecGBDTDataset(dataset_dir, DatasetType.TRAIN,sic_digits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd9f5ab-129f-44ea-93dc-a4352f45e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading sic1 index\n",
    "all_sics1 = val_dataset.all_data_dict[\"target\"]\n",
    "sic1_id_index = val_dataset.sic_id_index\n",
    "rev_sic1_id_index = {v:k for k,v in sic1_id_index.items()}\n",
    "all_sics1= np.array([rev_sic1_id_index[i] for i in all_sics1] )\n",
    "\n",
    "\n",
    "#Loadding sic2 index and ref (text)\n",
    "all_sics2 = dataset_sic_2.all_data_dict[\"target\"]\n",
    "sic2_id_index = dataset_sic_2.sic_id_index\n",
    "rev_sic2_id_index = {v:k for k,v in sic2_id_index.items()}\n",
    "all_sics2= np.array([rev_sic2_id_index[i] for i in all_sics2] )\n",
    "\n",
    "all_train_sics2 = train_dataset_sic_2.all_data_dict[\"target\"]\n",
    "all_train_sics2= np.array([rev_sic2_id_index[i] for i in all_train_sics2] )\n",
    "\n",
    "\n",
    "sic1_ref=load_sics_ref(sic_digits=1).set_index(\"sic1\").short_title_fr.to_dict()\n",
    "sic2_ref=load_sics_ref(sic_digits=2).set_index(\"sic2\").short_title_fr.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8ad5a3-e501-4cbf-867c-6bdd9a3286a3",
   "metadata": {},
   "source": [
    "## 6.1. Predictions histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50c2bb-f506-4609-a392-3ba4dabcb02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the accuracy of  the model for each sic2 class\n",
    "classes_correct_rate= {}\n",
    "classes_pred_as_3 = {}\n",
    "classes_nb_samples = {}\n",
    "\n",
    "df_stats_2 = pd.DataFrame(columns=[\"sic2\",\"recall\",\"pred_as_3\",\"nb_samples_val\",\"nb_samples_train\"])    \n",
    "\n",
    "for s in np.unique(all_train_sics2[all_train_sics2//10==2]):\n",
    "    index_s = all_sics2==s \n",
    "        \n",
    "    pred_as3_index = Y_val_pred[index_s]==sic1_id_index[3]\n",
    "    correct_index =  Y_val_pred[index_s]==Y_val[index_s]\n",
    "    \n",
    "    acc = np.mean(correct_index) if correct_index.sum()>0 else 0\n",
    "    ratio_pred_3=   np.mean(pred_as3_index) if pred_as3_index.sum()>0 else 0\n",
    "    nb_val_samples = np.sum(index_s)    \n",
    "    nb_train_samples = np.sum(all_train_sics2==s)\n",
    "    df_stats_2.loc[len(df_stats_2)] = [f\"{s} - {sic2_ref[s]}\",acc,ratio_pred_3,nb_val_samples,nb_train_samples]\n",
    "    # df_stats.loc[len(df_stats)] = [s,acc,ratio_pred_3,nb_val_samples,nb_train_samples]\n",
    "\n",
    "# sns.set(style=\"whitegrid\", color_codes=True)\n",
    "# Create a 2x2 grid of subplots\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "# #Rotate x labels\n",
    "for ax in axs.flat:\n",
    "    ax.tick_params(axis='x', rotation=80)\n",
    "\n",
    "# Plot 1 - correct_rate\n",
    "sns.barplot(x=\"sic2\", y=\"recall\", data=df_stats_2, ax=axs[0, 0])\n",
    "axs[0, 0].set_title(\"recall\")\n",
    "\n",
    "# Plot 2 - pred_as_3\n",
    "sns.barplot(x=\"sic2\", y=\"pred_as_3\", data=df_stats_2, ax=axs[0, 1])\n",
    "axs[0, 1].set_title(\"pred_as_3\")\n",
    "\n",
    "# Plot 3 - nb_samples_val\n",
    "sns.barplot(x=\"sic2\", y=\"nb_samples_val\", data=df_stats_2, ax=axs[1, 0])\n",
    "axs[1, 0].set_title(\"nb_samples_val\")\n",
    "\n",
    "# Plot 4 - nb_samples_train\n",
    "sns.barplot(x=\"sic2\", y=\"nb_samples_train\", data=df_stats_2, ax=axs[1, 1])\n",
    "axs[1, 1].set_title(\"nb_samples_train\")\n",
    "\n",
    "# Add some spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da9e017-2deb-4702-9544-908b5edc2a30",
   "metadata": {},
   "outputs": [],
   "source": [
    " ### Class 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045bcd7-9ad3-4c82-a299-a13767f06d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute the accuracy of  the model for each sic2 class\n",
    "classes_correct_rate= {}\n",
    "classes_pred_as_2 = {}\n",
    "classes_nb_samples = {}\n",
    "\n",
    "df_stats_3 = pd.DataFrame(columns=[\"sic2\",\"recall\",\"pred_as_2\",\"nb_samples_val\",\"nb_samples_train\"])    \n",
    "\n",
    "for s in np.unique(all_train_sics2[all_train_sics2//10==3]):\n",
    "    index_s = all_sics2==s \n",
    "        \n",
    "    pred_as2_index = Y_val_pred[index_s]==sic1_id_index[2]\n",
    "    correct_index =  Y_val_pred[index_s]==Y_val[index_s]\n",
    "    \n",
    "    acc = np.mean(correct_index) if correct_index.sum()>0 else 0\n",
    "    ratio_pred_2=   np.mean(pred_as2_index) if pred_as2_index.sum()>0 else 0\n",
    "    nb_val_samples = np.sum(index_s)    \n",
    "    nb_train_samples = np.sum(all_train_sics2==s)\n",
    "    df_stats_3.loc[len(df_stats_3)] = [f\"{s} - {sic2_ref[s]}\",acc,ratio_pred_2,nb_val_samples,nb_train_samples]\n",
    "    # df_stats.loc[len(df_stats)] = [s,acc,ratio_pred_3,nb_val_samples,nb_train_samples]\n",
    "\n",
    "# sns.set(style=\"whitegrid\", color_codes=True)\n",
    "# Create a 2x2 grid of subplots\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(20, 20))\n",
    "\n",
    "# #Rotate x labels\n",
    "for ax in axs.flat:\n",
    "    ax.tick_params(axis='x', rotation=80)\n",
    "\n",
    "# Plot 1 - correct_rate\n",
    "sns.barplot(x=\"sic2\", y=\"recall\", data=df_stats_3, ax=axs[0, 0])\n",
    "axs[0, 0].set_title(\"recall\")\n",
    "\n",
    "# Plot 2 - pred_as_3\n",
    "sns.barplot(x=\"sic2\", y=\"pred_as_2\", data=df_stats_3, ax=axs[0, 1])\n",
    "axs[0, 1].set_title(\"pred_as_2\")\n",
    "\n",
    "# Plot 3 - nb_samples_val\n",
    "sns.barplot(x=\"sic2\", y=\"nb_samples_val\", data=df_stats_3, ax=axs[1, 0])\n",
    "axs[1, 0].set_title(\"nb_samples_val\")\n",
    "\n",
    "# Plot 4 - nb_samples_train\n",
    "sns.barplot(x=\"sic2\", y=\"nb_samples_train\", data=df_stats_3, ax=axs[1, 1])\n",
    "axs[1, 1].set_title(\"nb_samples_train\")\n",
    "\n",
    "# Add some spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222ed89-fbc3-4443-bcb8-ec3e1d7a443e",
   "metadata": {},
   "source": [
    "## 6.2 Shapley values\n",
    "---------------------------\n",
    "- 22 : Textile Mills\n",
    "- 25 : Furniture & Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb16d7d-f2da-4468-8da9-cc13370032ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sic1_classes = [2,3]\n",
    "tartet_sic2_classes = [22,25]\n",
    "\n",
    "index_2 = all_sics1==2\n",
    "index_3 =  all_sics1==3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee072c1-904c-4ade-be4d-d0b92939b13e",
   "metadata": {},
   "source": [
    "### 6.2.1 Instance Shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0ee9c-ba02-4678-8e0b-22949426670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc382d2-a465-4d2b-b637-e2add08d1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sic1_ref :\",sic1_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1beb1b7-7861-429c-ad5b-81d7c6b26d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sics_ref[[\"sic1\",\"short_title_fr\"]].set_index(\"sic1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3741c4-c843-4fae-b73f-ebf12284ccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "import random\n",
    "\n",
    "def generate_shap_force_plot(explainer, samples, target_id, feature_names):\n",
    "    shap_values = explainer(samples)\n",
    "    expected_value = explainer.expected_value[target_id]\n",
    "    \n",
    "    row_idx = random.randint(0, samples.shape[0] - 1)\n",
    "    shap_value = shap_values[:,:,target_id].values[row_idx]\n",
    "    shap.initjs()\n",
    "    plot =shap.force_plot(base_value=expected_value,\n",
    "                           shap_values=shap_value,\n",
    "                           features=samples[row_idx, :],\n",
    "                           feature_names=feature_names,\n",
    "                           link=\"logit\",\n",
    "                           figsize=(10, 10))\n",
    "    display(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa5ca74-2a60-4edf-a17a-3f58a5a9cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Samples  25 Ok (good predictions)\n",
    "all_samples_25_ok = X_val[(all_sics2==25) & (Y_val_pred==sic1_id_index[2])]\n",
    "explainer = shap.TreeExplainer(model.model)\n",
    "shap_values_25_ok = explainer(all_samples_25_ok)\n",
    "\n",
    "generate_shap_force_plot(explainer, all_samples_25_ok, sic1_id_index[2], feature_names)\n",
    "generate_shap_force_plot(explainer, all_samples_25_ok, sic1_id_index[3], feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c1c08d-ebfe-4465-91d9-2974a8e82d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Samples  25 KO (misclassifications)\n",
    "all_samples_25_ko = X_val[(all_sics2==25) & (Y_val_pred==sic1_id_index[3])]\n",
    "explainer = shap.TreeExplainer(model.model)\n",
    "shap_values_25_ko = explainer(all_samples_25_ko)\n",
    "\n",
    "generate_shap_force_plot(explainer, all_samples_25_ko, sic1_id_index[2], feature_names)\n",
    "generate_shap_force_plot(explainer, all_samples_25_ko, sic1_id_index[3], feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4971bc0-1176-4b2c-9ea0-7dd73de74a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "498473b9-4271-4e99-b089-3fc41e251bdb",
   "metadata": {},
   "source": [
    "### 6.2.2. Global Average shap values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c2c5a-0407-4b0a-8107-1141195eca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_colors = [(1,0,0),(1,1,1),(0.,0.,1)]\n",
    "cmap_name = 'cmap'\n",
    "cmap = LinearSegmentedColormap.from_list(cmap_name, cmap_colors, N=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf17d59-a416-4874-adfd-a377580d9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=feature_names, data=X_val)\n",
    "df[\"sic1_true\"]=[rev_sic1_id_index[y] for y in Y_val]\n",
    "df[\"sic1_pred\"]= [rev_sic1_id_index[y] for y in Y_val_pred]\n",
    "df[\"sic2\"]= all_sics2\n",
    "def plot_average_shap_values(index, sort_column):\n",
    "    \"\"\"\n",
    "    Display average shapvalues for a specific index.\n",
    "    \"\"\"\n",
    "    explainer = shap.TreeExplainer(model.model)\n",
    "    value_samples = df.loc[index][feature_names]\n",
    "    shap_values = explainer.shap_values(value_samples)\n",
    "    mean_shap = {}\n",
    "    for sic1 in [2,3]:\n",
    "        target_id = sic1_id_index[sic1]\n",
    "        mean_shap[sic1] = shap_values[target_id].mean(axis=0)\n",
    "\n",
    "    df_tags_shap = pd.DataFrame({\"Tag\":feature_names, \"shap_sic1_2\":mean_shap[2],\n",
    "                                 \n",
    "                                    \"shap_sic1_3\":mean_shap[3]})\n",
    "\n",
    "    df_stats = value_samples.describe()[feature_names].transpose()[[\"mean\",\"std\",\"min\",\"max\",\"count\",\"50%\"]]\n",
    "    df_stats.index.name=\"Tag\"\n",
    "    df_tags_shap = pd.merge(df_stats,df_tags_shap, on=\"Tag\")\n",
    "    df_tags_shap.sort_values(by=sort_column,ascending=False, key=abs,inplace=True)\n",
    "    \n",
    "    df_tags_shap = df_tags_shap.style\\\n",
    "    .background_gradient(cmap, subset=\"shap_sic1_2\")\\\n",
    "    .background_gradient(cmap, subset=\"shap_sic1_3\")\\\n",
    "    .background_gradient(cmap, subset=\"mean\")\n",
    "\n",
    "    display(df_tags_shap)\n",
    "    return df_tags_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f7590-adff-47a3-a4ad-6f63166898f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#1.Class 2 shap values\n",
    "plot_average_shap_values(df.sic1_pred==2 , sort_column=\"shap_sic1_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604b2aa3-6409-4c3f-8366-d58e69a164de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2.Class 3 shap values\n",
    "plot_average_shap_values(df.sic1_pred==3 , sort_column=\"shap_sic1_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dcbb1e-a3c5-4e59-9702-6a115bd586ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3.Class 3 ok\n",
    "plot_average_shap_values((df.sic1_true==3)&(df.sic1_pred==3) , sort_column=\"shap_sic1_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897cbfc0-ddd4-4002-80bb-2c6d457c773d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3.Class 2 ok\n",
    "plot_average_shap_values((df.sic1_true==2)&(df.sic1_pred==2) , sort_column=\"shap_sic1_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f5592-0a71-4f58-9e90-370b76ad287f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4. Class 2 ko\n",
    "plot_average_shap_values((df.sic1_true==2)&(df.sic1_pred!=2) , sort_column=\"shap_sic1_2\").background_gradient(cmap, subset=\"shap_sic1_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d875598-1e5d-4e57-8e23-5808b7d95a76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##5. Class 25 \n",
    "plot_average_shap_values(df.sic2==25 , sort_column=\"shap_sic1_2\").background_gradient(cmap, subset=\"shap_sic1_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78468f61-70e1-40f9-b4a1-4e798e3429f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##6. Class 25 ok\n",
    "plot_average_shap_values((df.sic2==25)&(df.sic1_pred==2) , sort_column=\"shap_sic1_2\").background_gradient(cmap, subset=\"shap_sic1_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab64ef8-47dc-41f6-88d2-206047b61d3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##6. Class 25 ko\n",
    "plot_average_shap_values((df.sic2==25)&(df.sic1_pred!=2) , sort_column=\"shap_sic1_2\").background_gradient(cmap, subset=\"shap_sic1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacc68d0-75c7-4605-8c41-954167ca0e4e",
   "metadata": {},
   "source": [
    "### 6.3. Tags statistics Box plot (like in sec_data_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ca0b0-fa14-45eb-b777-f433756d661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn.objects as so\n",
    "import matplotlib as mpl\n",
    "from ipywidgets import interactive,fixed, interact_manual,interact, FloatSlider, SelectMultiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f95cda-6027-449b-a100-b98c447f816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags ordering according to Lightbm features importance plot.(Top 20 TAGS)\n",
    "MOST_IMPORTANT_TAGS = [\"InventoryNet\",\n",
    "              \"CommonStockValue\",\n",
    "              \"PropertyPlantAndEquipmentNet\",\n",
    "              \"Goodwill\",\n",
    "              \"TreasuryStockValue\",\n",
    "              \"AccumulatedOtherComprehensiveIncomeLossNetOfTax\",\n",
    "              \"AdditionalPaidInCapital\",\n",
    "              \"AccountsReceivableNetCurrent\",\n",
    "              \"IntangibleAssetsNetExcludingGoodwill\",\n",
    "              \"AccountsPayableCurrent\",\n",
    "              \"Liabilities\",\n",
    "              \"DeferredRevenueCurrent\",\n",
    "              \"EmployeeRelatedLiabilitiesCurrent\",\n",
    "              \"AllowanceForDoubtfulAccountsReceivableCurrent\",\n",
    "              \"MinorityInterest\",\n",
    "              \"RetainedEarningsAccumulatedDeficit\",\n",
    "              # \"AccumulatedDepreciationDepletionAndAmortizationPropertyPlanAndEquipment\",\n",
    "              \"AssetsCurrent\",\n",
    "              \"PropertyPlandAndEquipementGross\"]\n",
    "              \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a8c0e-f159-4cd2-b1d8-47623f48b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier(points, pct=90):\n",
    "    \"\"\"\n",
    "    Returns a boolean array with True if points are outliers and False \n",
    "    otherwise.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        points : An numobservations by numdimensions array of observations\n",
    "        pct : The percentage threshold used to determine whether a point is an outlier.\n",
    "            Points with a value below the specified percentage will be considered outliers.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        mask : A numobservations-length boolean array.\n",
    "    \"\"\"# Calculate the 90th percentile of the data\n",
    "    q90 = np.percentile(points.abs(), pct)\n",
    "\n",
    "    # Create a boolean mask indicating which values fall above the 90th percentile\n",
    "    mask = points.abs() >= q90\n",
    "    return mask\n",
    "    \n",
    "def show_singletag_stats(df,  tag, pct_outlier=0.95,whis=1.5, sic1_whitelist = [2,3],\n",
    "                         sic2_whitelist=[22,25]):\n",
    "    \"\"\"\n",
    "     Display the values distribution of a given account(tag)\n",
    "    :param samples  : A np.array of samples filtered \n",
    "    :paran account_name :  The name of the , tagaccount whose distribution will be displayed\n",
    "    \"\"\"\n",
    "    df =df[df.tag==tag]\n",
    "    all_df =[]\n",
    "    for sic1 in sic1_whitelist:\n",
    "        sub_df = df[df.sic1_true==sic1].copy()\n",
    "        \n",
    "        sub_df_ok = sub_df[sub_df.sic1_true==sub_df.sic1_pred].copy()\n",
    "        sub_df_ko = sub_df[sub_df.sic1_true!=sub_df.sic1_pred].copy()\n",
    "\n",
    "        sub_df.rename(columns={\"sic1_true\":\"sic\"},inplace=True)\n",
    "\n",
    "        sub_df_ok[\"sic\"] = sub_df_ok[\"sic1_true\"].apply(lambda x: f\"{x}_ok\")\n",
    "        sub_df_ko[\"sic\"] = sub_df_ko[\"sic1_true\"].apply(lambda x: f\"{x}_ko\")\n",
    "\n",
    "        all_df.append(sub_df)\n",
    "        all_df.append(sub_df_ok)\n",
    "        all_df.append(sub_df_ko)\n",
    "\n",
    "    for sic2 in sic2_whitelist:\n",
    "        sub_df = df[df.sic2==sic2].copy()\n",
    "        \n",
    "        sub_df_ok = sub_df[sub_df.sic1_true==sub_df.sic1_pred].copy()\n",
    "        sub_df_ko = sub_df[sub_df.sic1_true!=sub_df.sic1_pred].copy()\n",
    "\n",
    "        sub_df.rename(columns={\"sic2\":\"sic\"},inplace=True)\n",
    "\n",
    "        sub_df_ok[\"sic\"] = sub_df_ok[\"sic2\"].apply(lambda x: f\"{x}_ok\")\n",
    "        sub_df_ko[\"sic\"] = sub_df_ko[\"sic2\"].apply(lambda x: f\"{x}_ko\")\n",
    "        all_df.append(sub_df)\n",
    "        all_df.append(sub_df_ok)\n",
    "        all_df.append(sub_df_ko)\n",
    "\n",
    "    df = pd.concat(all_df)\n",
    "\n",
    "\n",
    "    fig = mpl.figure.Figure(figsize=(30, 20), dpi=100, layout=\"constrained\")\n",
    "    sf1, sf2  = fig.subfigures(1, 2)\n",
    "\n",
    "    # 1. Dot splots\n",
    "    so.Plot(df, x=\"net_change\") \\\n",
    "        .add(so.Bars(), so.Hist())\\\n",
    "        .facet(row=f\"sic\")\\\n",
    "        .share(x=False)\\\n",
    "        .share(y=False)\\\n",
    "        .on(sf1).plot()\n",
    "        \n",
    "    \n",
    "    ax = sf2.add_axes([0.1,0.1,0.8,0.8])\n",
    "    sns.boxplot(x=f\"sic\", \n",
    "                     y=\"net_change\",\n",
    "                     hue=\"sic\",\n",
    "                     ax=ax,\n",
    "                     whis=whis,\n",
    "                     data=df[(~is_outlier(df.net_change,pct=pct_outlier))],\n",
    "                     # log_scale=True,\n",
    "                    palette=\"tab10\",\n",
    "                    )\n",
    "    display(fig)\n",
    "    display(f\"**{tag}\")\n",
    "\n",
    "def show_tag_box_plot(df):\n",
    "    ##First unpivot\n",
    "    df = df.melt(value_vars=feature_names,value_name=\"net_change\",var_name=\"tag\",id_vars=[\"sic1_pred\",\"sic1_true\",\"sic2\"])\n",
    "    \n",
    "    def view_fn(tag, pct_outlier,whis=1.5, sic1_whitelist=[],sic2_whitelist=[]):\n",
    "        return show_singletag_stats(df,tag=tag,pct_outlier=pct_outlier,whis=whis\n",
    "                                    ,sic1_whitelist=sic1_whitelist\n",
    "                                    ,sic2_whitelist=sic2_whitelist)\n",
    "        \n",
    "                            \n",
    "    interact(view_fn, tag=MOST_IMPORTANT_TAGS,\n",
    "             sic_digit=[2],\n",
    "             pct_outlier= [95, 90, 80,100],\n",
    "             whis=FloatSlider(min=1,max=5, step=0.5, value=1.5),\n",
    "              sic1_whitelist= SelectMultiple(\n",
    "                    options=sorted(df.sic1_true.unique().tolist()),\n",
    "                    value=[2,3],\n",
    "                        #rows=10,\n",
    "                        description='Sic2',\n",
    "                    disabled=False),\n",
    "              sic2_whitelist= SelectMultiple(\n",
    "                    options=sorted(df.sic2.unique().tolist()),\n",
    "                    value=[22,25,33,36],\n",
    "                    description='Sic2',\n",
    "                    disabled=False\n",
    "                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9447721-199f-40e4-af26-c8b233c34a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_tag_box_plot(df)\n",
    "# df_melted = df.melt(value_vars=feature_names,value_name=\"net_change\",var_name=\"tag\",id_vars=[\"sic1_pred\",\"sic1_true\",\"sic2\"])\n",
    "# for tag in MOST_IMPORTANT_TAGS :\n",
    "#     show_singletag_stats(df_melted, tag, sic1_whitelist = [2,3],\n",
    "#                          sic2_whitelist=[22,25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8068ab-a898-49c7-8e57-c98cd8b8bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_features_summary(samples_1, samples_2, feature_name):\n",
    "    df1 = pd.DataFrame(columns=feature_names, data=samples_1)\n",
    "    df2 = pd.DataFrame(columns=feature_names, data=samples_2)\n",
    "    \n",
    "    df_desc= pd.concat([df1.describe()[[feature_name]],df2.describe()[[f25,feature_name]]],axis=1)\n",
    "    display(df_desc)\n",
    "\n",
    "    df1[\"set\"]=1\n",
    "    df2[\"set\"]=2\n",
    "\n",
    "    df_all=pd.concat( [df1[[feature_name,\"set\"]], df2[[feature_name,\"set\"]]])\n",
    "    sns.histplot(x=feature_name, data=df_all, hue=\"set\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f36d9-644e-4737-ae22-81fbe555e661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c067f4-20f2-4825-8d5e-74aa0b31d146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc3defb-3c8a-4cc5-9562-7c4f1c3479a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
